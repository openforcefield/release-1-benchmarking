# Constructing benchmark/test sets for OpenFF quantum chemistry benchmarks

Here, our key question is how to benchmark OpenFF performance on quantum chemistry data.
Specifically, we are interested in selecting (from available data) sets of molecules which contain similar chemistry to those which were fit on, and which are drug-like, to assess our performance after refitting.

We plan to construct a primary benchmark set (on similar chemistry relative to what we've fit to) and a full benchmark set (utilizing all suitable data).

Here, we will be drawing on available data (several QM data sets) and training sets to assist in selection of test/benchmark data.

Author: David L. Mobley (UCI)

## Draft procedure

Our initial draft procedure is as follows:

- Compute similarity of molecules in our dataset (potentially after additional filtering for drug-likeness if needed) to molecules in the training set; initially we will use OEGraphSim for this
- Retain those molecules with sufficient similarity for use in primary benchmark set. These will also be utilized in the full benchmark, of which the primary will be a subset.
- Those molecules with low similarity will be reserved for full benchmark set which is more challenging
- Potentially, an additional assessment of parameter usage will be applied: Molecules in the primary benchmark set should only utilize parameters which are well represented in the training set.

## Detailed plans/steps:

1. Obtain training set data and potential test set data
2. Obtain parameter usage statistics for training set data
3. Compute chemical graph similarity matrix of all molecules
4. Cluster all molecules based on graph similarity using `DBSCAN`
5. Pick potential primary set molecules as those which are in clusters with at least one training set molecule.
6. Check parameter usage of all potential primary benchmark set molecules; any which use especially unusual parameters get saved for full benchmark set


## Data availability

Some potential benchmark systems are still running on QCFractal as of this writing. Status can be assessed using info from the [QCArchive docs](https://qcarchivetutorials.readthedocs.io/en/latest/basic_examples/torsiondrive_datasets.html#Exploring-the-Dataset), specifically see the `status` functionality.

## Manifest

- `openff_unconstrained-1.0.0-RC1.offxml` from https://github.com/openforcefield/openforcefields; OpenFF 1.0 release candidate 1.
- `divide_sets.ipynb`, initial Jupyter notebook to attempt dividing up into primary and stretch sets.
- `target_smiles.txt`, SMILES strings of unique molecules used in OpenFF 1.0 RC1 fitting (from Yudong Qiu, Sept. 18, 2019)
- `cluster_pdfs`, if present: Auto-generated by `divide_sets.ipynb`; gives view of current clusters.
- `benchmark_set_pdfs`, if present: Auto-generated by `divide_sets.ipynb`; gives view of proposed benchmark sets (primary and full)
- `primary_torsiondrive_benchmark_1.txt`: Proposed "OpenFF Primary TorsionDrive Benchmark 1"
- `full_torsiondrive_benchmark_1.txt`: Proposed "OpenFF Full TorsionDrive Benchmark 1"
- `primary_optimization_benchmark_1.txt`: Proposed "OpenFF Primary Optimization Benchmark 1"
- `full_optimization_benchmark_1.txt`: Proposed "OpenFF Full Optimization Benchmark 1"
